\documentclass[12pt, oneside]{book}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%                                   IMPORTS
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\renewcommand\figurename{Fig.}

\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=3.5cm, right=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[slovak]{babel}
\usepackage{amsmath}

% enable including .pdf files, e.g. comenius logo (komlogo-new) and images
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}
\hypersetup{
    colorlinks = true,
    linkbordercolor = black,
    linkcolor = red,
    citecolor = gray,
    urlcolor = blue,
}

% value 1.25 should correspond to 1.5 line spacing
\linespread{1.25}

\addto\captionsslovak{\renewcommand{\figurename}{fig.}}
\graphicspath{{pictures/}}
\bibpunct{(}{)}{;}{a}{,}{,}

% TODO:
% what are these used for?
% - \usepackage[hang, flushmargin]{footmisc}
% - \usepackage{pdfpages}
% - \usepackage{lmodern} % should be nicer font, but nothing changed...


% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%                             VARIABLE DEFINITIONS
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\def\mfthesistype{Bachelor Thesis}
\def\mfauthor{Michal Hoľa}
\def\mfadvisor{Mgr. Peter Gergeľ}
\def\mfyear{2016}
\def\mfplacedate{Bratislava, \mfyear}
\def\programme{Applied Informatics}
\def\subject{9.2.9 \programme}
\def\department{Department of Applied Informatics}
\def\school{Comenius University in Bratislava}
\def\faculty{Faculty of Mathematics, Physics and Informatics}
\def\thesisname{
    Artifictial neural network as an opponent in Quoridor
}

\author{\mfauthor}
\title{\thesisname}
\date{\mfyear}

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%                                DOCUMENT BODY
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\begin{document}

  \input firstpages.tex
  \newpage

  \input abstract.tex
  \newpage

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%                                   PREFACE
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%                                   CONTENTS
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%                                 INTRODUCTION
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  \section{Introduction}
    \subsection{Quoridor Rules}

    \begin{wrapfigure}{R}{0.4\textwidth}
      \vspace*{-0.48cm}
      \centering
      \includegraphics[width=0.35\textwidth]{real_board.jpg}
      \vspace*{-0.60cm}
      \caption{real board}
      \label{fig:real_board}
      \vspace*{-0.60cm}
    \end{wrapfigure}

    Quoridor is abstract board strategy game for 2 or 4 players with size of
    9x9 (81) squares. This thesis covers 2 player version of this game.

    \begin{wrapfigure}{R}{0.4\textwidth}
      \vspace*{-0.98cm}
      \centering
      \includegraphics[width=0.35\textwidth]{start.png}
      \vspace*{-0.60cm}
      \caption{game start}
      \label{fig:game_start}
      \vspace*{-1.40cm}
    \end{wrapfigure}

    Each player starts with a single pawn in the center of the edge on the
    opposite side as the opponent.
    The goal for each player is to reach the opposite edge.

    Player also starts with 10 walls (fences) in the stock.
    Walls are two space wide and can be placed in the groove that runs between
    the spaces.
    Placed wall blocks pawns paths forcing them to go arount it.
    Walls once placed can not be moved nor removed.
    Wall can not be placed to the position already occupied or crossing by
    other wall.
    Also, wall can not cut off the only remaining path of any pawn to his goal.

    When player is on turn, he must place wall, if he has left some, or move
    his pawn to adjacent (not diagonal and unoccupied) space.
    If opponent's pawn stands on an adjacent space, current player can jump
    with his pawn to all the places where the opponent pawn can move.

  \subsection{Q-Learning}
    Q-Learning is reinforcement learning method. It learns an action-value
    (q-value) function for any finite Markov decision process used to find
    optimal policy for the agent. After it has learned the q-value function,
    it can follow the optimal strategy by choosing best q-value. ?citation?
    Algorithm is value iteration update for every observed state ?citation?:
    \begin{equation}
    Q_{t+1} \leftarrow Q_t(s_t, a_t) + \alpha \cdot (
        R_{t+1} + \gamma\cdot {\max_a}\,Q_t(s_{t+1}, a) - Q_t(s_t, a_t)
    )
    \end{equation}
    where $Q_t(s_t, a_t)$ is old value, $\alpha$ is learning rate, $R_{t+1}$ is
    reward after performing action $a_t$ in state $s_t$, $\gamma$ is discount
    factor and $\underset{a}{\max}\,Q_t(s_{t+1}, a)$ is maximum optimal future
    value.
    \newpage

  \subsection{Quoridor complexity}
    \begin{wrapfigure}{r}{0.5\textwidth}
      \vspace*{-1.45cm}
      \begin{equation}
        \label{eqn:mertensestimate}
        \begin{aligned}
          S_p &= 81 \cdot 80 = 6480
          \\
          S_f &= \sum_{i=0}^{20}\prod_{j=0}^{i}(128 - 4i) = 6.1582\cdot10^{38}
          \\
          S &= S_p \cdot S_f = \mathbf{3.9905 \cdot 10 ^{42}}
        \end{aligned}
      \end{equation}
      \vspace*{-2.45cm}
    \end{wrapfigure}

    Estimated game state complexity was $3.9905\cdot10^{42}$ [\cite{mertens}],
    however, this is very rough estimate, since it includes impossible states
    such as:
    \begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
      \setlength\itemsep{0em}
      \item both pawns in the winning positions
      \item pawn in the winning position where it could not end due to walls
      \item pawns not having the path to winning position
    \end{enumerate}

    Moreover, this estimate does include which player is on move and also how
    many walls have players in their stock. Both of these could make the game
    very different in the outcome. At least, $S_p$ could be corrected to not
    include both pawns in the winning positions to
    $S_p = 81\cdot80 - 9\cdot9 = 6399$, but this does not make significant
    difference with the former estimate ($3.9406\cdot10^{42}$).\\
    Lets assume, this estimate is precise enough and assume that we can
    evaluate $10^{6}$ states in one second. Then it would take around $10^{29}$
    years to evaluate every state.\\
    Also, lets assume it takes on average 50B of memory per state. Then we
    would need approximately $1.19703\cdot10^{44}$ bytes of memory to store all
    states in the computer.

  \subsection{Perceptron}

    \begin{wrapfigure}{l}{0.4\textwidth}
      \vspace*{-0.45cm}
      \centering
      \includegraphics[width=0.4\textwidth]{neural-net1.png}
      \vspace*{-1.45cm}
      \caption{ANN}
      \label{fig:network}
      \vspace*{-1.00cm}
    \end{wrapfigure}

    Artifitial neural network (ANN) is a family of models inspired by biological
    neural networks used in computer science to approximate functions with
    large number of inputs. Generally, artifitial neural network is presented
    as a system of interconnected neurons exchanging messages between each
    other. These connections have weights that can be adjusted based on
    experience which makes the network capable of learning.

    Perceptron is an algorithm for supervised learning of binary classifiers
    where one neuron has multiple weighted inputs and single output. Single
    perceptron can learn to decide between two linearly separable
    classes. Multiple perceptrons in multiple layers (MLP) use arbitrary
    activation function which makes it able to perform classification or
    regression based on the activation function chosen.

\renewcommand\bibname{References}
\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
